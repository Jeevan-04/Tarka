# 🧠 Tarka (तर्क)
### A Reflective AI Engine of Beliefs, Contradictions, and Reasoning

**Tarka** is a symbolic AI system that models cognition not through weights or layers — but through **beliefs**, **contradictions**, and **questions**.  
Inspired by Indian logic (*Tarka*) and built for explainability, it simulates a reflective mind that can reason, question itself, and evolve.

---

## 🧭 Philosophy

> Most AI models today are trained on massive data using black-box neural networks.  
> But the human mind doesn’t just learn — it *reasons*, *contradicts*, *questions*, and *reflects*.

Tarka reimagines intelligence as:
- A **graph of beliefs** with varying confidence
- A **logic engine** that detects contradictions and uncertainty
- A **question generator** that simulates curiosity
- A **dream module** for imagining new ideas
- A **meta-cognitive system** for reflecting on its own thoughts

---

## 🔑 Core Concepts

| Concept        | Description |
|----------------|-------------|
| **Belief (B)** | A statement with metadata: confidence, source, timestamp |
| **Belief Graph (G)** | A network of beliefs connected by `supports`, `contradicts`, `derived_from` edges |
| **Contradiction** | Occurs when two beliefs disagree, leading to confusion |
| **Question** | Generated when contradictions or low confidence appear |
| **Dreaming** | Simulation of hypothetical beliefs and their effect on the system |
| **Meta-Belief** | A belief about another belief (e.g., doubt, low confidence) |

---
